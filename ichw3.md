# ichw3

# 通用的高速缓存存储器(Cache)的结构及工作原理

### Cache简介：

·高速缓冲存储器(Cache)是存在于主存与CPU之间的一级存储器，由静态存储芯片(SRAM)组成，容量比较小但速度比主存高得多，接近于CPU的速度。计算机中，在速度方面，主存和CPU有大约一个数量级的差距。这个差距限制了CPU速度潜力的发挥。为了弥合这个差距，仅采用一种工艺的单一存储器是行不通的，必须进一步从计算机系统结构和组织上去研究。设置高速缓冲存储器（Cache）是解决存取速度的重要方法。

## 结构：

Cache主要由三部分组成：

Cache存储体：存放由主存调入的指令与数据块。

地址转换部件：建立目录表以实现主存地址到缓存地址的转换。

替换部件：在缓存已满时按一定策略进行数据块替换，并修改地址转换部件。

Cache和主存的结构基本相同，均含有数据及地址，但Cache中还有一项“地址信息”，即上述地址转换部件，用来存储该数据对应物理内存的地址。因此当CPU访问Cache时同时还可以得到该数据在主存中的地址，从而得到物理内存中的相应数据。因此CPU可以直接从Cache中读取正确数据并进行处理从而加快速度。

## 工作原理

首先，为了弄清楚Cache的工作原理，我们需要明白Cache是如何与主存的数据联系起来的。缓存和主存数据一一对应（映射）的方式主要有3种：

### ① 全相联映射

地址映象规则：主存的任意一块可以映象到Cache中的任意一块        

(1)主存与缓存分成相同大小的数据块。      

(2)主存的某一数据块可以装入缓存的任意一块空间中。        

全相联方式的对应关系如下图所示。

![image text](https://github.com/TimGinobili/ichw/blob/master/1.jpg)

可知，如果Cache的块数为C，主存的块数为M，则映象关系共有C×M种。

在全相联Cache中，存储的块与块之间，以及存储顺序或保存的存储器地址之间没有直接的关系。程序可以访问很多的子程序、堆栈和段，而它们是位于主存储器的不同部位上。因此，Cache保存着很多互不相关的数据块，Cache必须对每个块和块自身的地址加以存储。当请求数据时，Cache控制器要把请求地址同所有地址加以比较，进行确认。 
这种Cache结构的主要优点是，它能够在给定的时间内去存储主存器中的不同的块，命中率（即一段时间内命中————即需要的数据在Cache内————的次数与该时间段内CPU访问的总次数的比值）高；缺点是每一次请求数据同Cache中的地址进行比较需要相当的时间，速度较慢，成本高，因而应用少。

### ② 直接映射

地址映象规则：主存储器中一块只能映象到Cache的一个特定的块中。        

(1)主存与缓存分成相同大小的数据块。        

(2)主存容量应是缓存容量的整数倍，将主存空间按缓存的容量分成区 ，主存中每一区的块数与缓存的总块数相等。        

(3)主存中某区的一块存入缓存时只能存入缓存中块号相同的位置。

直接相联映象规则如下图。

![image text](https://github.com/TimGinobili/ichw/blob/master/2.jpg)

直接映像Cache不同于全相联Cache。地址仅需比较一次。

在直接映像Cache中,由于每个主存储器的块在Cache中仅存在一个位置，因而把地址的比较次数减少为一次。其做法是，为Cache中的每个块位置分配一个索引字段，用Tag字段区分存放在Cache位置上的不同的块,单路直接映像把主存储器分成若干页,主存储器的每一页与Cache存储器的大小相同。匹配的主存储器的偏移量可以直接映像为Cache偏移量。Cache的Tag存储器(偏移量)保存着主存储器的页地址(页号)。

以上可以看出。直接映像Cache优于全相联Cache，能进行快速查找，其缺点是当主存储器的组之间做频繁调用时，Cache控制器必须做多次转换。

### ③ 组相联映射

地址映象规则：(1)主存和Cache按同样大小划分成块。         

(2)主存和Cache按同样大小划分成组。       

(3)主存容量是缓存容量的整数倍，将主存空间按缓冲区的大小分成区，主存中每一区的组数与缓存的组数相同。

(4)当主存的数据调入缓存时，主存与缓存的组号应相等，也就是各区中的某一块只能存入缓存的同组号的空间内，但组内各块地址之间则可以任意存放，
即从主存的组到Cache的组之间采用直接映象方式；在两个对应的组内部采用全相联映象方式。

组相联映象规则如下图。

![image text](https://github.com/TimGinobili/ichw/blob/master/3.jpg)

图中缓存共分Cg个组，每组包含有Gb块；
主存是缓存的Me倍，所以共分有Me个区，
每个区有Cg组，每组有Gb块。那么，
主存地址格式中应包含4个字段：区号、区内组号、组内块号和块内地址。
而缓存中包含3个字段：组号、组内块号、块内地址。主存地址与缓存地址的转换有两部分，组地址是按直接映象方式，按地址进行访问，而块地址是采用全相联方式，按内容访问。

组相联Cache是介于全相联Cache和直接映像Cache之间的一种结构。这种类型的Cache使用了几组直接映像的块，对于某一个给定的索引号，可以允许有几个块位置，因而可以增加命中率和系统效率。 

其优点是块的冲突概率比较低，块的利用率大幅度提高，块失效率明显降低；缺点是实现难度和造价要比直接映象方式高。

在了解了三种基本的映射方式之后，我们就可以理解Cache的具体工作过程了。如下图：

![image text](https://github.com/TimGinobili/ichw/blob/master/4.jpg)

简而言之，首先CPU对Cache发起访问，通过上述的映射机制来判断是否命中。

若命中，则直接从Cache读取数据，若未命中则需要从主存中调取数据到Cache中。

而需要特别注意，当需要调取数据到Cache中时，需要先判断Cache中是否还有空间。

若有，则直接调取；若没有，则调用Cache替换策略，将Cache中的一部分数据调出以腾出空间，再继续调取。

其中，替换策略的算法主要如下：
（1）传统替换算法及其直接演化，其代表算法有 ：

①LRU（ Least Recently Used）算法：将最近最少使用的内容替换出Cache ；

②LFU（ Lease Frequently Used）算法：将访问次数最少的内容替换出Cache；

③如果Cache中所有内容都是同一天被缓存的，则将最大的文档替换出Cache，否则按LRU算法进行替换 。

④FIFO( First In First Out)：遵循先入先出原则，若当前Cache被填满，则替换最早进入Cache的那个。

（2）基于缓存内容关键特征的替换算法，其代表算法有：

①Size替换算法：将最大的内容替换出Cache；

②LRU— MIN替换算法：该算法力图使被替换的文档个数最少。设待缓存文档的大小为S，对Cache中缓存的大小至少是S的文档，根据LRU算法进行替换；如果没有大小至少为S的对象，则从大小至少为S/2的文档中按照LRU算法进行替换；

③LRU—Threshold替换算法：和LRU算法一致，只是大小超过一定阈值的文档不能被缓存；

④Lowest Lacency First替换算法：将访问延迟最小的文档替换出Cache。

（3）基于代价的替换算法，该类算法使用一个代价函数对Cache中的对象进行评估，最后根据代价值的大小决定替换对象。其代表算法有：

①Hybrid算法：算法对Cache中的每一个对象赋予一个效用函数，将效用最小的对象替换出Cache；

②Lowest Relative Value算法：将效用值最低的对象替换出Cache；

③Least Normalized Cost Replacement（LCNR）算法：该算法使用一个关于文档访问频次、传输时间和大小的推理函数来确定替换文档；

④Bolot等人 提出了一种基于文档传输时间代价、大小、和上次访问时间的权重推理函数来确定文档替换；

⑤Size—Adjust LRU（SLRU）算法：对缓存的对象按代价与大小的比率进行排序，并选取比率最小的对象进行替换。

至此便是Cache的工作流程，由于其速度快且容量大于寄存器，Cache大幅提升了计算机的工作效率，意义非凡。
